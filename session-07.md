
# ConnectIntensive Session 07

#### 10:00 am - 10:15 am Introductory presentation, general housekeeping
 - Students will check in with Udacity App
 - Students will set goals with Udacity App 
 - Homework for coming week
     - Submit/complete unsupervised learning project by Dec 10
     - Reinforcement Learning: Intro to Reinforcement Learning
     - Reinforcement Learning: Markov Decision Processes
     - Do not do the Reinforcement Learning subsection. This content will be used in next week’s session.
 - Present where we are in the Connect Intensive schedule
 - Master schedule can be found in the Google Docs link
 - Students should have completed supervised learning project by now
 - Reminder about Slack status checkin
 
#### 10:15 - 11:00 Notebook lesson - Data Clustering - comparison of different algorithms
The notebooks will be posted in the ConnectIntensive repo on my GitHub account
Notebook for this week — ** session-07-part-01 **
 - Students should work in pairs on the notebook
 - Agglomerative Clustering
 - GMMs
 - Silhouette scores


#### 11:00 - 11:30 Notebook review and Discussion on Data Clustering
- Questions that came up 
- Walk through solutions and discussion

#### 11:30 - noon Introduction to the Unsupervised Learning project
 - General overview of project
 - Highlight Sections that require students to apply their intuition


#### noon - 1:00pm Lunch break
- Check in with Udacity app for late comers


#### 1:00 pm - 2:00 pm Notebook lesson on Feature Selection/Feature Transformation
The notebooks will be posted in the ConnectIntensive repo on my GitHub account
Notebook for this week — I’ll notify you as soon as it’s up.
- Students should work in pairs on the notebook. 


#### 2:00pm-2:30pm Review notebook lesson and Discussion
 - Questions that came up
 - Walkthrough notebook


#### 2:30 pm - 3:00 pm Recap and Lookahead - what to focus on in the video lectures
 - Discussion prompts:
    - “Share something you learned in the session today!”
    - “Is there any topic from the lectures so far that you’re not feeling too certain about?
    - “What’s one topic you want to explore more after today’s session?”
 - Getting started on Reinforcement Learning
     - You are expected to watch the first two sections of video lectures before our next session (Dec 10). The first one is the vanilla introduction to reinforcement learning -- should go pretty quickly. The second one is about Markov Decision Processes and is quite dense.
    
     - The link to the video lectures under the main topic heading of ** Reinforcement Learning ** starts in the middle of the series of lectures created by Georgia Tech. If you get disoriented and feel like you somehow jumped into the middle of an ongoing conversation, there is some reprieve. The context for these lectures are the lectures from the Udacity class labelled ** [Machine Learning](https://classroom.udacity.com/courses/ud262/) ** (not the Thrun/Morgan series labelled ** Introduction to Machine Learning **). This course created by Georgia Tech and Udacity has three major parts "SL", "UL" and "RL"; the sections for each part have these two letter prefixes to indicate which section you are in. The reinforcement learning lecture videos are from the "RL" group. If you decide to watch the videos under "RL" in order, you may want to skip anything related to BURLAP -- those sections will not be too useful for the smartcab project.
- Have pen and paper handy or your cut & paste tools ready. Stop the videos and write down the main points. While some of the jokes are just funny, there is often some interesting point that one of them mentions almost as a joke that may be worth following up on. 
- You don't need to be able to derive all the Bellmann equations for this project -- you just need to know enough about them to be able to code the Q-learning updates and action selection and justify your choices and algorithms.



