
# ConnectIntensive Session 08

## ABC's of Q-Learning

#### 10:00 am - 10:15 am Introductory presentation, general housekeeping
 - Students check in with Udacity App
 - Students set goals with Udacity App - homework for coming week
     - Reinforcement Learning: Reinforcement Learning
     - Reinforcement Learning: Game Theory
     - Smartcab project review
 - Present where we are in the Connect Intensive schedule
 - Students should have submitted/completed unsupervised learning project by this weeken

 
#### 10:15 - 11:00 Notebook lesson -  Calculating rewards for Markov Decision Processes
- The notebooks will be posted in the ConnectIntensive repo on my GitHub account
- Notebook for this week — I’ll notify you as soon as it’s up.
- Students should work in pairs on the notebook. whichever they prefer
- During this time, do 1:1 meetings with the students, and also answer questions and troubleshoot


#### 11:00 - 11:30 Notebook Review and Discussion on MDP and Reinforcement Learning
- Questions that came up 
- Walk through solutions and discussion

#### 11:30 - noonInstalling pygame and verifying installation
 - overview of project
 - Highlight Sections that require students to apply their intuition



#### noon - 1:00pm Lunch break
- Check in with Udacity app for late comers


#### 1:00 pm - 2:00 pm Notebook lesson on Q Learning - Simple Game
The notebooks will be posted in the ConnectIntensive repo on my GitHub account
Notebook for this week — I’ll notify you as soon as it’s up.
- Students should work in pairs on the notebook. 


#### 2:00pm-2:30pm Review notebook lesson and Discussion of Reinforcement Learning
 - Questions that came up
 - Walkthrough notebook


#### 2:30 pm - 3:00 pm Recap and Lookahead - what to focus on in the video lectures
 - Discussion prompts:
    - “Share something you learned in the session today!”
    - “Is there any topic from the lectures so far that you’re not feeling too certain about?
    - “What’s one topic you want to explore more after today’s session?”
 - Game Theory
     - You are expected to watch the third and last section of video lectures before our next session (Dec 17). This concludes the set of lectures for the ML ND. If you were following thse videos on the Udacity class labelled ** [Machine Learning](https://classroom.udacity.com/courses/ud262/) ** (not the Thrun/Morgan series labelled ** Introduction to Machine Learning **), please note that the section on Game Theory for that class is more extensive and exceeds what you are expected to learn for the ML ND.
     .
- Have pen and paper handy or your cut & paste tools ready. Stop the videos and write down the main points. While some of the jokes are just funny, there is often some interesting point that one of them mentions almost as a joke that may be worth following up on. 
- You don't need to be able to derive all the Bellmann equations for this project -- you just need to know enough about them to be able to code the Q-learning updates and action selection and justify your choices and algorithms.

##### Continued Learning

There is another set of good video lectures by [D Silver](https://www.youtube.com/watch?v=2pWv7GOvuf0&index=1&list=PLMZdRRhAoLnKFxZlmFoFp0uHVvN2PSE9T) (thanks Nick!) available on Youtube that give a broader introduction to the subject. There are 10 lectures, 1.5 hrs each. If you want to learn more about RL, this may be a good place to start. 


```python

```
